# Buddy configuration file
# Copy this file to buddy.toml and fill in your values.

[server]
# Address the server listens on (default: "127.0.0.1")
# host = "127.0.0.1"
# Port the server listens on (default: 3000)
# port = 3000

# --- Provider ---
# Select a provider by setting type. Default is "openai".

# Option 1: OpenAI (or any OpenAI-compatible API that requires an API key)
[provider]
type = "openai"
api_key = "your-api-key-here"
model = "gpt-4"
endpoint = "https://api.openai.com/v1"
# System prompt sent at the start of every conversation (optional)
# system_prompt = "You are a helpful, friendly AI assistant."

# Option 2: LM Studio (local OpenAI-compatible server, no API key needed)
# [provider]
# type = "lmstudio"
# model = "deepseek-coder"
# endpoint = "http://localhost:1234/v1"
# system_prompt = "You are a helpful, friendly AI assistant."

# --- Storage ---
# [storage]
# Path to the SQLite database file (default: "buddy.db")
# database = "buddy.db"

# --- Skills ---
# Skills are optional. Only skills with configuration are enabled.
# A skill with no config section is disabled entirely.

# read_file — Read files from allowed directories
# [skills.read_file]
# allowed_directories = ["/home/user/documents", "/home/user/projects"]

# write_file — Write files to allowed directories (creates parent dirs as needed)
# [skills.write_file]
# allowed_directories = ["/home/user/sandbox"]

# fetch_url — HTTP GET from allowlisted domains (10s timeout)
# [skills.fetch_url]
# allowed_domains = ["example.com", "api.github.com"]
