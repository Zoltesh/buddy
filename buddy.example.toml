# Buddy configuration file
# Copy this file to buddy.toml and fill in your values.

[server]
# Address the server listens on (default: "127.0.0.1")
# host = "127.0.0.1"
# Port the server listens on (default: 3000)
# port = 3000

[provider]
# Your LLM provider API key (required)
api_key = "your-api-key-here"
# Model identifier to use (required)
model = "gpt-4"
# Provider API endpoint URL (required)
endpoint = "https://api.openai.com/v1"
# System prompt sent at the start of every conversation (optional)
# system_prompt = "You are a helpful, friendly AI assistant."
