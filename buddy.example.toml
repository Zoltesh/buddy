# Buddy configuration file
# Copy this file to buddy.toml and fill in your values.

[server]
# Address the server listens on (default: "127.0.0.1")
# host = "127.0.0.1"
# Port the server listens on (default: 3000)
# port = 3000

# --- Chat ---
# System prompt sent at the start of every conversation (optional).
# [chat]
# system_prompt = "You are a helpful, friendly AI assistant."

# --- Models ---
# Each model slot contains an ordered list of providers.
# The first provider is the default; remaining entries are fallbacks.

# Chat model (required) — used for conversations.

# Option 1: OpenAI (or any OpenAI-compatible API that requires an API key)
[[models.chat.providers]]
type = "openai"
model = "gpt-4"
endpoint = "https://api.openai.com/v1"
api_key_env = "OPENAI_API_KEY"    # reads API key from this environment variable

# Option 2: LM Studio (local OpenAI-compatible server, no API key needed)
# [[models.chat.providers]]
# type = "lmstudio"
# model = "deepseek-coder"
# endpoint = "http://localhost:1234/v1"

# Embedding model (optional) — used for semantic search.
# If omitted, embedding-dependent features are unavailable.
# [[models.embedding.providers]]
# type = "openai"
# model = "text-embedding-3-small"
# endpoint = "https://api.openai.com/v1"
# api_key_env = "OPENAI_API_KEY"

# --- Storage ---
# [storage]
# Path to the SQLite database file (default: "buddy.db")
# database = "buddy.db"

# --- Skills ---
# Skills are optional. Only skills with configuration are enabled.
# A skill with no config section is disabled entirely.

# read_file — Read files from allowed directories
# [skills.read_file]
# allowed_directories = ["/home/user/documents", "/home/user/projects"]

# write_file — Write files to allowed directories (creates parent dirs as needed)
# [skills.write_file]
# allowed_directories = ["/home/user/sandbox"]

# fetch_url — HTTP GET from allowlisted domains (10s timeout)
# [skills.fetch_url]
# allowed_domains = ["example.com", "api.github.com"]
